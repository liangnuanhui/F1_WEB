#!/usr/bin/env python3
"""
FastF1 æ•°æ®æ¢ç´¢å·¥å…·
ç”¨äºåˆ†æ FastF1 çš„å®é™…æ•°æ®ç»“æ„ï¼Œä¸ºæ•°æ®å»ºæ¨¡æä¾›ä¾æ®
ç»“æœä¿å­˜ä¸º Markdown æ–‡ä»¶
"""

import sys
import os
import logging
import pandas as pd
from datetime import datetime
from io import StringIO

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ° Python è·¯å¾„
sys.path.insert(0, os.path.dirname(os.path.abspath(__file__)))

# é…ç½®æ—¥å¿—
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)

# å®šä¹‰æˆ‘ä»¬éœ€è¦çš„èµ›å­£èŒƒå›´
TARGET_SEASONS = [2023, 2024, 2025]

# ç”¨äºæ•è·è¾“å‡ºçš„ StringIO å¯¹è±¡
output_buffer = StringIO()

def log_and_capture(message, level="INFO"):
    """è®°å½•æ—¥å¿—å¹¶æ•è·è¾“å‡º"""
    timestamp = datetime.now().strftime("%Y-%m-%d %H:%M:%S")
    formatted_message = f"[{timestamp}] {level}: {message}"
    
    # è¾“å‡ºåˆ°æ§åˆ¶å°
    print(formatted_message)
    
    # åŒæ—¶å†™å…¥åˆ° Markdown ç¼“å†²åŒº
    output_buffer.write(formatted_message + "\n")
    
    # è®°å½•åˆ°æ—¥å¿—
    if level == "ERROR":
        logger.error(message)
    elif level == "WARNING":
        logger.warning(message)
    else:
        logger.info(message)

def explore_data_structure(data, name):
    """æ¢ç´¢æ•°æ®ç»“æ„"""
    log_and_capture(f"\n{'='*60}")
    log_and_capture(f"ğŸ“Š {name} æ•°æ®ç»“æ„åˆ†æ")
    log_and_capture(f"{'='*60}")
    
    try:
        # æ£€æŸ¥æ˜¯å¦æ˜¯ FastF1 çš„ ErgastMultiResponse ç±»å‹
        if hasattr(data, '__class__') and 'ErgastMultiResponse' in str(data.__class__):
            log_and_capture(f"ğŸ“‹ æ•°æ®ç±»å‹: ErgastMultiResponse")
            
            # æ˜¾ç¤ºæè¿°ä¿¡æ¯
            if hasattr(data, 'description') and not data.description.empty:
                log_and_capture(f"ğŸ“ æè¿°ä¿¡æ¯ (å…±{len(data.description)}ä¸ªæ¯”èµ›):")
                log_and_capture(f"```")
                log_and_capture(data.description.to_string())
                log_and_capture(f"```")
            
            # æ˜¾ç¤ºå†…å®¹æ•°æ®
            if hasattr(data, 'content') and data.content:
                log_and_capture(f"ğŸ“ å†…å®¹æ•°é‡: {len(data.content)} ä¸ªæ•°æ®é›†")
                
                for idx, df in enumerate(data.content):
                    log_and_capture(f"\nğŸ“Š ç¬¬ {idx + 1} ä¸ªæ•°æ®é›†:")
                    log_and_capture(f"   æ•°æ®ç±»å‹: DataFrame")
                    log_and_capture(f"   æ•°æ®å½¢çŠ¶: {df.shape}")
                    log_and_capture(f"   åˆ—å: {list(df.columns)}")
                    
                    # æ˜¾ç¤ºå¯¹åº”çš„æè¿°ä¿¡æ¯
                    if hasattr(data, 'description') and idx < len(data.description):
                        race_info = data.description.iloc[idx]
                        log_and_capture(f"   å¯¹åº”æ¯”èµ›: ç¬¬{race_info.get('round', 'N/A')}è½® - {race_info.get('raceName', 'N/A')}")
                    
                    print(f"\n   æ•°æ®ç±»å‹:")
                    for col, dtype in df.dtypes.items():
                        log_and_capture(f"     {col}: {dtype}")
                    
                    if not df.empty:
                        log_and_capture(f"\n   ç¤ºä¾‹æ•°æ® (å‰3è¡Œ):")
                        log_and_capture(f"```")
                        log_and_capture(df.head(3).to_string())
                        log_and_capture(f"```")
                        
                        log_and_capture(f"\n   æ•°æ®ç»Ÿè®¡:")
                        log_and_capture(f"   éç©ºå€¼ç»Ÿè®¡:")
                        for col in df.columns:
                            try:
                                non_null_count = df[col].notna().sum()
                                null_count = df[col].isna().sum()
                                total_count = len(df)
                                if total_count > 0:
                                    percentage = (non_null_count / total_count) * 100
                                    log_and_capture(f"     {col}: {non_null_count}/{total_count} ({percentage:.1f}%) éç©º, {null_count} ç©ºå€¼")
                                else:
                                    log_and_capture(f"     {col}: 0/0 (0.0%) éç©º, 0 ç©ºå€¼")
                            except Exception as e:
                                log_and_capture(f"     {col}: ç»Ÿè®¡å¤±è´¥ - {e}", "ERROR")
                        
                        # æ£€æŸ¥å”¯ä¸€å€¼
                        log_and_capture(f"\n   å”¯ä¸€å€¼ç»Ÿè®¡:")
                        for col in df.columns:
                            try:
                                unique_count = df[col].nunique()
                                log_and_capture(f"     {col}: {unique_count} ä¸ªå”¯ä¸€å€¼")
                                if unique_count <= 10 and unique_count > 0:
                                    unique_values = df[col].dropna().unique()
                                    # ç¡®ä¿å€¼æ˜¯å¯å“ˆå¸Œçš„
                                    safe_values = []
                                    for val in unique_values:
                                        try:
                                            hash(val)
                                            safe_values.append(str(val))
                                        except:
                                            safe_values.append(f"<ä¸å¯å“ˆå¸Œç±»å‹: {type(val).__name__}>")
                                    log_and_capture(f"       å”¯ä¸€å€¼: {safe_values}")
                            except Exception as e:
                                log_and_capture(f"     {col}: å”¯ä¸€å€¼ç»Ÿè®¡å¤±è´¥ - {e}", "ERROR")
                        
                        # æ£€æŸ¥æ•°å€¼åˆ—çš„ç»Ÿè®¡ä¿¡æ¯
                        try:
                            numeric_cols = df.select_dtypes(include=['number']).columns
                            if len(numeric_cols) > 0:
                                log_and_capture(f"\n   æ•°å€¼åˆ—ç»Ÿè®¡:")
                                log_and_capture(f"```")
                                log_and_capture(df[numeric_cols].describe().to_string())
                                log_and_capture(f"```")
                        except Exception as e:
                            log_and_capture(f"   æ•°å€¼åˆ—ç»Ÿè®¡å¤±è´¥: {e}", "ERROR")
                    else:
                        log_and_capture(f"   æ•°æ®ä¸ºç©º")
            else:
                log_and_capture("âŒ æ²¡æœ‰å†…å®¹æ•°æ®", "ERROR")
        
        elif isinstance(data, pd.DataFrame):
            log_and_capture(f"ğŸ“‹ æ•°æ®ç±»å‹: DataFrame")
            log_and_capture(f"ğŸ“ æ•°æ®å½¢çŠ¶: {data.shape}")
            log_and_capture(f"ğŸ“ åˆ—å: {list(data.columns)}")
            
            log_and_capture(f"\nğŸ“Š æ•°æ®ç±»å‹:")
            for col, dtype in data.dtypes.items():
                log_and_capture(f"   {col}: {dtype}")
            
            if not data.empty:
                log_and_capture(f"\nğŸ“‹ ç¤ºä¾‹æ•°æ® (å‰3è¡Œ):")
                log_and_capture(f"```")
                log_and_capture(data.head(3).to_string())
                log_and_capture(f"```")
                
                log_and_capture(f"\nğŸ” æ•°æ®ç»Ÿè®¡:")
                log_and_capture(f"   éç©ºå€¼ç»Ÿè®¡:")
                for col in data.columns:
                    try:
                        non_null_count = data[col].notna().sum()
                        null_count = data[col].isna().sum()
                        total_count = len(data)
                        if total_count > 0:
                            percentage = (non_null_count / total_count) * 100
                            log_and_capture(f"     {col}: {non_null_count}/{total_count} ({percentage:.1f}%) éç©º, {null_count} ç©ºå€¼")
                        else:
                            log_and_capture(f"     {col}: 0/0 (0.0%) éç©º, 0 ç©ºå€¼")
                    except Exception as e:
                        log_and_capture(f"     {col}: ç»Ÿè®¡å¤±è´¥ - {e}", "ERROR")
                
                # æ£€æŸ¥å”¯ä¸€å€¼
                log_and_capture(f"\nğŸ¯ å”¯ä¸€å€¼ç»Ÿè®¡:")
                for col in data.columns:
                    try:
                        unique_count = data[col].nunique()
                        log_and_capture(f"     {col}: {unique_count} ä¸ªå”¯ä¸€å€¼")
                        if unique_count <= 10 and unique_count > 0:
                            unique_values = data[col].dropna().unique()
                            # ç¡®ä¿å€¼æ˜¯å¯å“ˆå¸Œçš„
                            safe_values = []
                            for val in unique_values:
                                try:
                                    hash(val)
                                    safe_values.append(str(val))
                                except:
                                    safe_values.append(f"<ä¸å¯å“ˆå¸Œç±»å‹: {type(val).__name__}>")
                            log_and_capture(f"       å”¯ä¸€å€¼: {safe_values}")
                    except Exception as e:
                        log_and_capture(f"     {col}: å”¯ä¸€å€¼ç»Ÿè®¡å¤±è´¥ - {e}", "ERROR")
                
                # æ£€æŸ¥æ•°å€¼åˆ—çš„ç»Ÿè®¡ä¿¡æ¯
                try:
                    numeric_cols = data.select_dtypes(include=['number']).columns
                    if len(numeric_cols) > 0:
                        log_and_capture(f"\nğŸ“ˆ æ•°å€¼åˆ—ç»Ÿè®¡:")
                        log_and_capture(f"```")
                        log_and_capture(data[numeric_cols].describe().to_string())
                        log_and_capture(f"```")
                except Exception as e:
                    log_and_capture(f"   æ•°å€¼åˆ—ç»Ÿè®¡å¤±è´¥: {e}", "ERROR")
            else:
                log_and_capture(f"   æ•°æ®ä¸ºç©º")
        
        else:
            log_and_capture(f"ğŸ“‹ æ•°æ®ç±»å‹: {type(data)}")
            log_and_capture(f"ğŸ“ æ•°æ®å†…å®¹: {data}")
            
    except Exception as e:
        log_and_capture(f"âŒ æ•°æ®ç»“æ„åˆ†æå¤±è´¥: {e}", "ERROR")
        import traceback
        error_trace = traceback.format_exc()
        log_and_capture(f"é”™è¯¯è¯¦æƒ…:\n{error_trace}", "ERROR")

def explore_fastf1_data():
    """æ¢ç´¢ FastF1 æ•°æ®"""
    try:
        import fastf1
        from fastf1.ergast import Ergast
        
        log_and_capture("ğŸ” å¼€å§‹æ¢ç´¢ FastF1 æ•°æ®ç»“æ„...")
        log_and_capture(f"ğŸ¯ ç›®æ ‡èµ›å­£: {TARGET_SEASONS}")
        
        # å¯ç”¨ç¼“å­˜
        fastf1.Cache.enable_cache('./cache')
        ergast = Ergast()
        
        # 1. æ¢ç´¢èµ›å­£æ•°æ® (åªè·å–ç›®æ ‡èµ›å­£)
        log_and_capture("ğŸ“… 1. æ¢ç´¢èµ›å­£æ•°æ®...")
        try:
            # è·å–æ‰€æœ‰èµ›å­£ï¼Œç„¶åè¿‡æ»¤å‡ºæˆ‘ä»¬éœ€è¦çš„
            all_seasons = ergast.get_seasons()
            target_seasons = all_seasons[all_seasons['season'].isin(TARGET_SEASONS)]
            
            log_and_capture(f"\nğŸ¯ ç›®æ ‡èµ›å­£æ•°æ®:")
            log_and_capture(f"ğŸ“ æ•°æ®å½¢çŠ¶: {target_seasons.shape}")
            log_and_capture(f"ğŸ“ åˆ—å: {list(target_seasons.columns)}")
            log_and_capture(f"ğŸ“‹ ç›®æ ‡èµ›å­£: {list(target_seasons['season'].values)}")
            
            explore_data_structure(target_seasons, "ç›®æ ‡èµ›å­£æ•°æ® (Target Seasons)")
        except Exception as e:
            log_and_capture(f"âŒ è·å–èµ›å­£æ•°æ®å¤±è´¥: {e}", "ERROR")
        
        # 2. æ¢ç´¢èµ›é“æ•°æ® (ä½¿ç”¨2025èµ›å­£ä½œä¸ºç¤ºä¾‹)
        log_and_capture("ğŸ 2. æ¢ç´¢èµ›é“æ•°æ®...")
        try:
            circuits = ergast.get_circuits(season=2025)
            explore_data_structure(circuits, "èµ›é“æ•°æ® (Circuits - 2025)")
        except Exception as e:
            log_and_capture(f"âŒ è·å–èµ›é“æ•°æ®å¤±è´¥: {e}", "ERROR")
        
        # 3. æ¢ç´¢è½¦é˜Ÿæ•°æ® (ä½¿ç”¨2025èµ›å­£ä½œä¸ºç¤ºä¾‹)
        log_and_capture("ğŸï¸ 3. æ¢ç´¢è½¦é˜Ÿæ•°æ®...")
        try:
            constructors = ergast.get_constructor_info(season=2025)
            explore_data_structure(constructors, "è½¦é˜Ÿæ•°æ® (Constructors - 2025)")
        except Exception as e:
            log_and_capture(f"âŒ è·å–è½¦é˜Ÿæ•°æ®å¤±è´¥: {e}", "ERROR")
        
        # 4. æ¢ç´¢è½¦æ‰‹æ•°æ® (ä½¿ç”¨2025èµ›å­£ä½œä¸ºç¤ºä¾‹)
        log_and_capture("ğŸ‘¤ 4. æ¢ç´¢è½¦æ‰‹æ•°æ®...")
        try:
            drivers = ergast.get_driver_info(season=2025)
            explore_data_structure(drivers, "è½¦æ‰‹æ•°æ® (Drivers - 2025)")
        except Exception as e:
            log_and_capture(f"âŒ è·å–è½¦æ‰‹æ•°æ®å¤±è´¥: {e}", "ERROR")
        
        # 5. æ¢ç´¢æ¯”èµ›æ—¥ç¨‹æ•°æ® (ä½¿ç”¨2025èµ›å­£ä½œä¸ºç¤ºä¾‹)
        log_and_capture("ğŸ 5. æ¢ç´¢æ¯”èµ›æ—¥ç¨‹æ•°æ®...")
        try:
            # FastF1 æ–¹å¼
            races_fastf1 = fastf1.get_event_schedule(2025)
            explore_data_structure(races_fastf1, "æ¯”èµ›æ—¥ç¨‹æ•°æ® (FastF1 - 2025)")
            
            # Ergast æ–¹å¼
            races_ergast = ergast.get_race_schedule(season=2025)
            explore_data_structure(races_ergast, "æ¯”èµ›æ—¥ç¨‹æ•°æ® (Ergast - 2025)")
        except Exception as e:
            log_and_capture(f"âŒ è·å–æ¯”èµ›æ—¥ç¨‹æ•°æ®å¤±è´¥: {e}", "ERROR")
        
        # 6. æ¢ç´¢ç§¯åˆ†æ¦œæ•°æ® (ä½¿ç”¨2025èµ›å­£ä½œä¸ºç¤ºä¾‹)
        log_and_capture("ğŸ† 6. æ¢ç´¢ç§¯åˆ†æ¦œæ•°æ®...")
        try:
            driver_standings = ergast.get_driver_standings(season=2025)
            explore_data_structure(driver_standings, "è½¦æ‰‹ç§¯åˆ†æ¦œæ•°æ® (Driver Standings - 2025)")
            
            constructor_standings = ergast.get_constructor_standings(season=2025)
            explore_data_structure(constructor_standings, "è½¦é˜Ÿç§¯åˆ†æ¦œæ•°æ® (Constructor Standings - 2025)")
        except Exception as e:
            log_and_capture(f"âŒ è·å–ç§¯åˆ†æ¦œæ•°æ®å¤±è´¥: {e}", "ERROR")
        
        # 7. æ¢ç´¢æ¯”èµ›ç»“æœæ•°æ® (ä½¿ç”¨2025èµ›å­£ä½œä¸ºç¤ºä¾‹)
        log_and_capture("ğŸ 7. æ¢ç´¢æ¯”èµ›ç»“æœæ•°æ®...")
        try:
            results = ergast.get_race_results(season=2025)
            explore_data_structure(results, "æ¯”èµ›ç»“æœæ•°æ® (Race Results - 2025)")
        except Exception as e:
            log_and_capture(f"âŒ è·å–æ¯”èµ›ç»“æœæ•°æ®å¤±è´¥: {e}", "ERROR")
        
        # 8. æ¢ç´¢æ’ä½èµ›ç»“æœæ•°æ® (ä½¿ç”¨2025èµ›å­£ä½œä¸ºç¤ºä¾‹)
        log_and_capture("ğŸ 8. æ¢ç´¢æ’ä½èµ›ç»“æœæ•°æ®...")
        try:
            qualifying_results = ergast.get_qualifying_results(season=2025)
            explore_data_structure(qualifying_results, "æ’ä½èµ›ç»“æœæ•°æ® (Qualifying Results - 2025)")
        except Exception as e:
            log_and_capture(f"âŒ è·å–æ’ä½èµ›ç»“æœæ•°æ®å¤±è´¥: {e}", "ERROR")
        
        # 9. æ¢ç´¢å†²åˆºèµ›ç»“æœæ•°æ® (ä½¿ç”¨2025èµ›å­£ä½œä¸ºç¤ºä¾‹)
        log_and_capture("ğŸ 9. æ¢ç´¢å†²åˆºèµ›ç»“æœæ•°æ®...")
        try:
            sprint_results = ergast.get_sprint_results(season=2025)
            explore_data_structure(sprint_results, "å†²åˆºèµ›ç»“æœæ•°æ® (Sprint Results - 2025)")
        except Exception as e:
            log_and_capture(f"âŒ è·å–å†²åˆºèµ›ç»“æœæ•°æ®å¤±è´¥: {e}", "ERROR")
        
        log_and_capture("âœ… æ•°æ®æ¢ç´¢å®Œæˆ")
        
    except Exception as e:
        log_and_capture(f"âŒ æ•°æ®æ¢ç´¢å¤±è´¥: {e}", "ERROR")
        import traceback
        traceback.print_exc()

def generate_model_suggestions():
    """ç”Ÿæˆæ¨¡å‹å»ºè®®"""
    log_and_capture(f"\n{'='*60}")
    log_and_capture(f"ğŸ’¡ æ•°æ®å»ºæ¨¡å»ºè®®")
    log_and_capture(f"{'='*60}")
    
    log_and_capture(f"""
åŸºäº FastF1 æ•°æ®ç»“æ„åˆ†æï¼Œå»ºè®®é‡‡ç”¨ä»¥ä¸‹å»ºæ¨¡ç­–ç•¥ï¼š

## 1. åŸºç¡€ç»´åº¦è¡¨ (ç‹¬ç«‹å®ä½“)

### Season (èµ›å­£)
- ä¸»é”®: year (INTEGER)
- å­—æ®µ: name, description, start_date, end_date
- ç‰¹ç‚¹: ç‹¬ç«‹å­˜åœ¨ï¼Œå…¶ä»–è¡¨çš„åŸºç¡€
- èŒƒå›´: 2023-2025èµ›å­£

### Circuit (èµ›é“)
- ä¸»é”®: circuit_id (VARCHAR)
- å­—æ®µ: name, location, country, length, corners
- ç‰¹ç‚¹: ç‹¬ç«‹å­˜åœ¨ï¼Œå¯è·¨èµ›å­£ä½¿ç”¨

### Constructor (è½¦é˜Ÿ)
- ä¸»é”®: constructor_id (VARCHAR)
- å­—æ®µ: name, nationality, base, power_unit
- ç‰¹ç‚¹: ç‹¬ç«‹å­˜åœ¨ï¼Œå¯è·¨èµ›å­£ä½¿ç”¨

## 2. ä¾èµ–ç»´åº¦è¡¨ (éœ€è¦å…³è”)

### Driver (è½¦æ‰‹)
- ä¸»é”®: driver_id (VARCHAR)
- å¤–é”®: constructor_id, season_id
- å­—æ®µ: first_name, last_name, nationality, number
- ç‰¹ç‚¹: ä¾èµ–è½¦é˜Ÿå’Œèµ›å­£

### Race (æ¯”èµ›)
- ä¸»é”®: race_id (VARCHAR)
- å¤–é”®: circuit_id, season_id
- å­—æ®µ: name, round_number, race_date, status
- ç‰¹ç‚¹: ä¾èµ–èµ›é“å’Œèµ›å­£

## 3. äº‹å®è¡¨ (ä¸šåŠ¡äº‹ä»¶)

### Result (æ¯”èµ›ç»“æœ)
- ä¸»é”®: id (AUTO_INCREMENT)
- å¤–é”®: race_id, driver_id, constructor_id
- å­—æ®µ: position, points, status, laps_completed
- ç‰¹ç‚¹: è®°å½•å…·ä½“æ¯”èµ›ç»“æœ

### QualifyingResult (æ’ä½èµ›ç»“æœ)
- ä¸»é”®: id (AUTO_INCREMENT)
- å¤–é”®: race_id, driver_id, constructor_id
- å­—æ®µ: position, q1_time, q2_time, q3_time
- ç‰¹ç‚¹: è®°å½•æ’ä½èµ›ç»“æœ

### SprintResult (å†²åˆºèµ›ç»“æœ)
- ä¸»é”®: id (AUTO_INCREMENT)
- å¤–é”®: race_id, driver_id, constructor_id
- å­—æ®µ: position, points, status, laps_completed
- ç‰¹ç‚¹: è®°å½•å†²åˆºèµ›ç»“æœ

### DriverStanding (è½¦æ‰‹ç§¯åˆ†æ¦œ)
- ä¸»é”®: id (AUTO_INCREMENT)
- å¤–é”®: driver_id, constructor_id
- å­—æ®µ: season, position, points, wins
- ç‰¹ç‚¹: è®°å½•ç§¯åˆ†æ¦œçŠ¶æ€

### ConstructorStanding (è½¦é˜Ÿç§¯åˆ†æ¦œ)
- ä¸»é”®: id (AUTO_INCREMENT)
- å¤–é”®: constructor_id
- å­—æ®µ: season, position, points, wins
- ç‰¹ç‚¹: è®°å½•è½¦é˜Ÿç§¯åˆ†æ¦œçŠ¶æ€

## 4. åŒæ­¥é¡ºåºå»ºè®®

1. Season (ç‹¬ç«‹) - 2023, 2024, 2025
2. Circuit (ç‹¬ç«‹)
3. Constructor (ç‹¬ç«‹)
4. Driver (ä¾èµ– Constructor, Season)
5. Race (ä¾èµ– Circuit, Season)
6. Result (ä¾èµ– Driver, Constructor, Race)
7. QualifyingResult (ä¾èµ– Driver, Constructor, Race)
8. SprintResult (ä¾èµ– Driver, Constructor, Race)
9. Standings (ä¾èµ– Driver, Constructor)

## 5. å…³é”®è®¾è®¡åŸåˆ™

- ä½¿ç”¨è‡ªç„¶é”®ä½œä¸ºä¸šåŠ¡æ ‡è¯† (driver_id, constructor_id)
- ä½¿ç”¨è‡ªå¢IDä½œä¸ºç‰©ç†ä¸»é”®
- å»ºç«‹é€‚å½“çš„å¤–é”®çº¦æŸ
- è€ƒè™‘æ•°æ®çš„å†å²æ€§å’Œæ—¶æ•ˆæ€§
- ä¼˜åŒ–æŸ¥è¯¢æ€§èƒ½çš„ç´¢å¼•è®¾è®¡
- å¤„ç† ErgastMultiResponse çš„å¤æ‚æ•°æ®ç»“æ„
- åªåŒæ­¥ç›®æ ‡èµ›å­£æ•°æ® (2023-2025)ï¼Œé¿å…å†å²æ•°æ®å†—ä½™

## 6. æ•°æ®èŒƒå›´æ§åˆ¶

- èµ›å­£èŒƒå›´: 2023-2025
- é¿å…è·å–è¿‡å¤šå†å²æ•°æ®
- æé«˜åŒæ­¥æ•ˆç‡å’Œæ€§èƒ½
- å‡å°‘å­˜å‚¨ç©ºé—´å ç”¨
""")

def main():
    """ä¸»å‡½æ•°"""
    log_and_capture("ğŸš€ å¼€å§‹ FastF1 æ•°æ®æ¢ç´¢...")
    log_and_capture(f"ğŸ¯ ç›®æ ‡èµ›å­£: {TARGET_SEASONS}")
    
    # æ¢ç´¢æ•°æ®ç»“æ„
    explore_fastf1_data()
    
    # ç”Ÿæˆå»ºæ¨¡å»ºè®®
    generate_model_suggestions()
    
    log_and_capture("âœ… æ•°æ®æ¢ç´¢å’Œå»ºè®®ç”Ÿæˆå®Œæˆ")
    
    # ä¿å­˜ç»“æœåˆ° Markdown æ–‡ä»¶
    try:
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        filename = f"fastf1_data_exploration_{timestamp}.md"
        
        # åˆ›å»º Markdown æ–‡ä»¶å¤´éƒ¨
        markdown_content = f"""# FastF1 æ•°æ®ç»“æ„æ¢ç´¢æŠ¥å‘Š

ç”Ÿæˆæ—¶é—´: {datetime.now().strftime("%Y-%m-%d %H:%M:%S")}
ç›®æ ‡èµ›å­£: {TARGET_SEASONS}

## æ¢ç´¢ç»“æœ

"""
        
        # æ·»åŠ æ•è·çš„è¾“å‡ºå†…å®¹
        markdown_content += output_buffer.getvalue()
        
        # å†™å…¥æ–‡ä»¶
        with open(filename, 'w', encoding='utf-8') as f:
            f.write(markdown_content)
        
        log_and_capture(f"ğŸ“„ ç»“æœå·²ä¿å­˜åˆ°: {filename}")
        
    except Exception as e:
        log_and_capture(f"âŒ ä¿å­˜ Markdown æ–‡ä»¶å¤±è´¥: {e}", "ERROR")

if __name__ == "__main__":
    main() 