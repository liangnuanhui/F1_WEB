"""
F1å®˜ç½‘èµ›é“ä¿¡æ¯æŠ“å–æœåŠ¡ v2.0 - æ”¹è¿›ç‰ˆ

æ”¹è¿›å†…å®¹ï¼š
1. ä¿®å¤å›½å®¶åç§°æ˜ å°„é—®é¢˜ï¼Œæ”¯æŒå¤šèµ›é“å¯¹åº”ä¸€ä¸ªå›½å®¶
2. å¢å¼ºé”™è¯¯å¤„ç†å’Œé‡è¯•æœºåˆ¶
3. æ·»åŠ è¯¦ç»†çš„æ—¥å¿—è®°å½•å’Œæ•°æ®éªŒè¯
4. æ”¹è¿›æ‰¹é‡å¤„ç†çš„ç¨³å®šæ€§
5. æ·»åŠ è¶…æ—¶å’Œé¢‘ç‡é™åˆ¶ä¿æŠ¤
"""

import asyncio
import aiohttp
import logging
from typing import Dict, Optional, List, Tuple
from pathlib import Path
import re
from bs4 import BeautifulSoup
from dataclasses import dataclass
import time
from urllib.parse import urljoin

logger = logging.getLogger(__name__)


@dataclass
class CircuitInfo:
    """èµ›é“ä¿¡æ¯æ•°æ®ç±»"""
    circuit_length: Optional[float] = None  # km
    first_grand_prix: Optional[int] = None
    number_of_laps: Optional[int] = None
    fastest_lap_time: Optional[str] = None
    fastest_lap_driver: Optional[str] = None
    fastest_lap_year: Optional[int] = None
    race_distance: Optional[float] = None  # km
    layout_image_url: Optional[str] = None
    layout_image_path: Optional[str] = None
    
    def is_complete(self) -> bool:
        """æ£€æŸ¥æ˜¯å¦è·å–åˆ°å®Œæ•´ä¿¡æ¯"""
        required_fields = [
            self.circuit_length,
            self.first_grand_prix,
            self.number_of_laps,
            self.race_distance
        ]
        return all(field is not None for field in required_fields)
    
    def missing_fields(self) -> List[str]:
        """è¿”å›ç¼ºå¤±çš„å­—æ®µåˆ—è¡¨"""
        missing = []
        if self.circuit_length is None:
            missing.append("èµ›é“é•¿åº¦")
        if self.first_grand_prix is None:
            missing.append("é¦–æ¬¡GP")
        if self.number_of_laps is None:
            missing.append("åœˆæ•°")
        if self.race_distance is None:
            missing.append("æ¯”èµ›è·ç¦»")
        if self.fastest_lap_time is None:
            missing.append("æœ€å¿«åœˆé€Ÿ")
        return missing


class F1CircuitScraperV2:
    """F1å®˜ç½‘èµ›é“ä¿¡æ¯æŠ“å–å™¨ v2.0"""
    
    def __init__(self, images_dir: str = "static/circuit_images"):
        self.base_url = "https://www.formula1.com"
        self.circuit_image_base_url = "https://media.formula1.com/image/upload/c_fit,h_704/q_auto/v1740000000/content/dam/fom-website/2018-redesign-assets/Circuit%20maps%2016x9/"
        self.session: Optional[aiohttp.ClientSession] = None
        self.images_dir = Path(images_dir)
        self.images_dir.mkdir(parents=True, exist_ok=True)
        
        # æ”¹è¿›çš„æ˜ å°„å…³ç³» - æ”¯æŒèµ›é“IDåˆ°å›½å®¶å’ŒURLçš„ç›´æ¥æ˜ å°„
        self.circuit_mapping = {
            # å·´æ—
            "bahrain": {
                "country_match": ["bahrain"],
                "url_name": "bahrain",
                "image_name": "Bahrain_Circuit.webp"
            },
            # æ²™ç‰¹é˜¿æ‹‰ä¼¯
            "jeddah": {
                "country_match": ["saudi arabia"],
                "url_name": "saudi-arabia", 
                "image_name": "Saudi_Arabia_Circuit.webp"
            },
            # æ¾³å¤§åˆ©äºš
            "albert_park": {
                "country_match": ["australia"],
                "url_name": "australia",
                "image_name": "Australia_Circuit.webp"
            },
            # é˜¿å¡æ‹œç–†
            "baku": {
                "country_match": ["azerbaijan"],
                "url_name": "azerbaijan",
                "image_name": "Baku_Circuit.webp"
            },
            # ç¾å›½ - è¿ˆé˜¿å¯†
            "miami": {
                "country_match": ["usa"],
                "url_name": "miami",
                "image_name": "Miami_Circuit.webp"
            },
            # æ„å¤§åˆ© - ä¼Šè«æ‹‰
            "imola": {
                "country_match": ["italy"],
                "url_name": "emiliaromagna",  # F1å®˜ç½‘ä½¿ç”¨çš„URLåç§° (æ— è¿å­—ç¬¦)
                "image_name": "Emilia_Romagna_Circuit.webp"
            },
            # æ‘©çº³å“¥
            "monaco": {
                "country_match": ["monaco"],
                "url_name": "monaco",
                "image_name": "Monaco_Circuit.webp"
            },
            # åŠ æ‹¿å¤§
            "villeneuve": {
                "country_match": ["canada"],
                "url_name": "canada",
                "image_name": "Canada_Circuit.webp"
            },
            # è¥¿ç­ç‰™
            "catalunya": {
                "country_match": ["spain"],
                "url_name": "spain",
                "image_name": "Spain_Circuit.webp"
            },
            # å¥¥åœ°åˆ©
            "red_bull_ring": {
                "country_match": ["austria"],
                "url_name": "austria",
                "image_name": "Austria_Circuit.webp"
            },
            # è‹±å›½
            "silverstone": {
                "country_match": ["uk", "great britain"],
                "url_name": "great-britain",
                "image_name": "Great_Britain_Circuit.webp"
            },
            # åŒˆç‰™åˆ©
            "hungaroring": {
                "country_match": ["hungary"],
                "url_name": "hungary",
                "image_name": "Hungary_Circuit.webp"
            },
            # æ¯”åˆ©æ—¶
            "spa": {
                "country_match": ["belgium"],
                "url_name": "belgium",
                "image_name": "Belgium_Circuit.webp"
            },
            # è·å…°
            "zandvoort": {
                "country_match": ["netherlands"], 
                "url_name": "netherlands",
                "image_name": "Netherlands_Circuit.webp"
            },
            # æ„å¤§åˆ© - è’™æ‰
            "monza": {
                "country_match": ["italy"],
                "url_name": "italy",
                "image_name": "Italy_Circuit.webp"
            },
            # æ–°åŠ å¡
            "marina_bay": {
                "country_match": ["singapore"],
                "url_name": "singapore",
                "image_name": "Singapore_Circuit.webp"
            },
            # ç¾å›½ - å¥¥æ–¯æ±€
            "americas": {
                "country_match": ["usa"],
                "url_name": "united-states",
                "image_name": "USA_Circuit.webp"
            },
            # å¢¨è¥¿å“¥
            "rodriguez": {
                "country_match": ["mexico"],
                "url_name": "mexico",
                "image_name": "Mexico_Circuit.webp"
            },
            # å·´è¥¿
            "interlagos": {
                "country_match": ["brazil"],
                "url_name": "brazil",
                "image_name": "Brazil_Circuit.webp"
            },
            # ç¾å›½ - æ‹‰æ–¯ç»´åŠ æ–¯
            "vegas": {
                "country_match": ["usa"],
                "url_name": "las-vegas",
                "image_name": "Las_Vegas_Circuit.webp"
            },
            # å¡å¡”å°”
            "losail": {
                "country_match": ["qatar"],
                "url_name": "qatar",
                "image_name": "Qatar_Circuit.webp"
            },
            # é˜¿è”é…‹
            "yas_marina": {
                "country_match": ["uae", "abu dhabi"],
                "url_name": "united-arab-emirates",
                "image_name": "Abu_Dhabi_Circuit.webp"
            },
            # ä¸­å›½
            "shanghai": {
                "country_match": ["china"],
                "url_name": "china",
                "image_name": "China_Circuit.webp"
            },
            # æ—¥æœ¬
            "suzuka": {
                "country_match": ["japan"],
                "url_name": "japan",
                "image_name": "Japan_Circuit.webp"
            }
        }
    
    async def __aenter__(self):
        """å¼‚æ­¥ä¸Šä¸‹æ–‡ç®¡ç†å™¨å…¥å£"""
        connector = aiohttp.TCPConnector(limit=10, limit_per_host=3)
        timeout = aiohttp.ClientTimeout(total=60, connect=10, sock_read=30)
        
        self.session = aiohttp.ClientSession(
            connector=connector,
            timeout=timeout,
            headers={
                'User-Agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36',
                'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,image/apng,*/*;q=0.8',
                'Accept-Language': 'en-US,en;q=0.9',
                'Accept-Encoding': 'gzip, deflate, br',
                'DNT': '1',
                'Connection': 'keep-alive',
                'Upgrade-Insecure-Requests': '1'
            }
        )
        return self
    
    async def __aexit__(self, exc_type, exc_val, exc_tb):
        """å¼‚æ­¥ä¸Šä¸‹æ–‡ç®¡ç†å™¨é€€å‡º"""
        if self.session:
            await self.session.close()
    
    def find_circuit_mapping_by_country(self, country: str) -> Optional[Tuple[str, Dict]]:
        """æ ¹æ®å›½å®¶åç§°æŸ¥æ‰¾èµ›é“æ˜ å°„"""
        country_lower = country.lower()
        
        for circuit_id, mapping in self.circuit_mapping.items():
            if country_lower in [c.lower() for c in mapping["country_match"]]:
                return circuit_id, mapping
        
        return None
    
    def find_circuit_mapping_by_id(self, circuit_id: str) -> Optional[Dict]:
        """æ ¹æ®èµ›é“IDæŸ¥æ‰¾æ˜ å°„"""
        return self.circuit_mapping.get(circuit_id)
    
    def get_circuit_page_url(self, circuit_id: str) -> Optional[str]:
        """æ ¹æ®èµ›é“IDè·å–F1å®˜ç½‘é¡µé¢URL"""
        mapping = self.find_circuit_mapping_by_id(circuit_id)
        if mapping:
            return f"{self.base_url}/en/racing/2025/{mapping['url_name']}"
        return None
    
    def get_circuit_image_url(self, circuit_id: str) -> Optional[str]:
        """æ ¹æ®èµ›é“IDè·å–å¸ƒå±€å›¾URL"""
        mapping = self.find_circuit_mapping_by_id(circuit_id)
        if mapping:
            return self.circuit_image_base_url + mapping["image_name"]
        return None
    
    async def download_image_with_retry(self, image_url: str, filename: str, max_retries: int = 3) -> Optional[str]:
        """å¸¦é‡è¯•æœºåˆ¶çš„å›¾ç‰‡ä¸‹è½½"""
        for attempt in range(max_retries):
            try:
                if not self.session:
                    return None
                
                logger.info(f"ğŸ“¥ ä¸‹è½½å›¾ç‰‡ (å°è¯• {attempt + 1}/{max_retries}): {filename}")
                
                async with self.session.get(image_url) as response:
                    if response.status == 200:
                        file_path = self.images_dir / filename
                        content = await response.read()
                        
                        with open(file_path, 'wb') as f:
                            f.write(content)
                        
                        file_size = len(content) / 1024  # KB
                        logger.info(f"âœ… ä¸‹è½½æˆåŠŸ: {filename} ({file_size:.1f}KB)")
                        return str(file_path)
                    else:
                        logger.warning(f"âŒ HTTPé”™è¯¯ {response.status}: {image_url}")
                        
            except asyncio.TimeoutError:
                logger.warning(f"â° ä¸‹è½½è¶…æ—¶ (å°è¯• {attempt + 1}/{max_retries}): {filename}")
            except Exception as e:
                logger.warning(f"âŒ ä¸‹è½½å¤±è´¥ (å°è¯• {attempt + 1}/{max_retries}): {e}")
            
            if attempt < max_retries - 1:
                await asyncio.sleep(2 ** attempt)  # æŒ‡æ•°é€€é¿
        
        logger.error(f"ğŸ’¥ ä¸‹è½½å¤±è´¥ï¼Œå·²è¾¾æœ€å¤§é‡è¯•æ¬¡æ•°: {filename}")
        return None
    
    def extract_circuit_data(self, text_content: str) -> CircuitInfo:
        """ä»ç½‘é¡µæ–‡æœ¬ä¸­æå–èµ›é“æ•°æ®"""
        circuit_info = CircuitInfo()
        
        try:
            # æå–èµ›é“é•¿åº¦ (Circuit Length)
            length_match = re.search(r'Circuit Length\s*([0-9.]+)\s*km', text_content, re.I)
            if length_match:
                circuit_info.circuit_length = float(length_match.group(1))
                logger.debug(f"  âœ“ èµ›é“é•¿åº¦: {circuit_info.circuit_length}km")
            
            # æå–é¦–æ¬¡å¤§å¥–èµ›å¹´ä»½ (First Grand Prix)
            first_gp_match = re.search(r'First Grand Prix\s*(\d{4})', text_content, re.I)
            if first_gp_match:
                circuit_info.first_grand_prix = int(first_gp_match.group(1))
                logger.debug(f"  âœ“ é¦–æ¬¡GP: {circuit_info.first_grand_prix}")
            
            # æå–åœˆæ•° (Number of Laps)
            laps_match = re.search(r'Number of Laps\s*(\d+)', text_content, re.I)
            if laps_match:
                circuit_info.number_of_laps = int(laps_match.group(1))
                logger.debug(f"  âœ“ åœˆæ•°: {circuit_info.number_of_laps}")
            
            # æå–æœ€å¿«åœˆé€Ÿ (Fastest lap time) - ä½¿ç”¨æ”¹è¿›çš„æ­£åˆ™è¡¨è¾¾å¼
            fastest_lap_patterns = [
                r'Fastest lap time\s*\n?\s*(\d+:\d+\.\d+)\s*\n?\s*([^(]+?)\s*\((\d+)\)',
                r'Fastest.*?(\d+:\d+\.\d+).*?([A-Za-z ]+)\s*\((\d+)\)',
                r'(\d+:\d+\.\d+)\s+([A-Za-z ]+(?:[A-Za-z ]+)?)\s*\((\d{4})\)'
            ]
            
            for pattern in fastest_lap_patterns:
                fastest_lap_match = re.search(pattern, text_content, re.I)
                if fastest_lap_match:
                    circuit_info.fastest_lap_time = fastest_lap_match.group(1)
                    circuit_info.fastest_lap_driver = fastest_lap_match.group(2).strip()
                    circuit_info.fastest_lap_year = int(fastest_lap_match.group(3))
                    logger.debug(f"  âœ“ æœ€å¿«åœˆé€Ÿ: {circuit_info.fastest_lap_time} by {circuit_info.fastest_lap_driver} ({circuit_info.fastest_lap_year})")
                    break
            
            # æå–æ¯”èµ›è·ç¦» (Race Distance)
            distance_match = re.search(r'Race Distance\s*([0-9.]+)\s*km', text_content, re.I)
            if distance_match:
                circuit_info.race_distance = float(distance_match.group(1))
                logger.debug(f"  âœ“ æ¯”èµ›è·ç¦»: {circuit_info.race_distance}km")
                
        except Exception as e:
            logger.error(f"âŒ æ•°æ®æå–å¤±è´¥: {e}")
        
        return circuit_info
    
    async def scrape_circuit_info_with_retry(self, circuit_id: str, max_retries: int = 3) -> Optional[CircuitInfo]:
        """å¸¦é‡è¯•æœºåˆ¶çš„èµ›é“ä¿¡æ¯æŠ“å–"""
        
        for attempt in range(max_retries):
            try:
                logger.info(f"ğŸ” æŠ“å–èµ›é“ä¿¡æ¯ {circuit_id} (å°è¯• {attempt + 1}/{max_retries})")
                
                # è·å–é¡µé¢URL
                page_url = self.get_circuit_page_url(circuit_id)
                if not page_url:
                    logger.error(f"âŒ æœªæ‰¾åˆ°èµ›é“ {circuit_id} çš„URLæ˜ å°„")
                    return None
                
                if not self.session:
                    logger.error("âŒ HTTPä¼šè¯æœªåˆå§‹åŒ–")
                    return None
                
                logger.info(f"ğŸ“„ è®¿é—®é¡µé¢: {page_url}")
                
                # è·å–é¡µé¢å†…å®¹
                async with self.session.get(page_url) as response:
                    if response.status != 200:
                        logger.warning(f"âŒ HTTPé”™è¯¯ {response.status}: {page_url}")
                        if attempt < max_retries - 1:
                            await asyncio.sleep(2 ** attempt)
                            continue
                        return None
                    
                    html = await response.text()
                    logger.info(f"âœ… é¡µé¢è·å–æˆåŠŸï¼Œå†…å®¹é•¿åº¦: {len(html)}")
                
                # è§£æé¡µé¢å†…å®¹
                soup = BeautifulSoup(html, 'html.parser')
                text_content = soup.get_text()
                
                # æå–æ•°æ®
                circuit_info = self.extract_circuit_data(text_content)
                
                # è®¾ç½®å¸ƒå±€å›¾URL
                circuit_info.layout_image_url = self.get_circuit_image_url(circuit_id)
                
                # ä¸‹è½½å¸ƒå±€å›¾
                if circuit_info.layout_image_url:
                    img_filename = f"{circuit_id}_circuit.webp"
                    downloaded_path = await self.download_image_with_retry(
                        circuit_info.layout_image_url, img_filename
                    )
                    if downloaded_path:
                        circuit_info.layout_image_path = downloaded_path
                
                # éªŒè¯æ•°æ®å®Œæ•´æ€§
                missing_fields = circuit_info.missing_fields()
                if missing_fields:
                    logger.warning(f"âš ï¸ ç¼ºå¤±å­—æ®µ {circuit_id}: {', '.join(missing_fields)}")
                else:
                    logger.info(f"âœ… æ•°æ®å®Œæ•´ {circuit_id}")
                
                # è¾“å‡ºæ‘˜è¦
                logger.info(f"ğŸ“Š {circuit_id} æŠ“å–æ‘˜è¦:")
                logger.info(f"   ğŸ“ èµ›é“é•¿åº¦: {circuit_info.circuit_length or 'N/A'} km")
                logger.info(f"   ğŸ é¦–æ¬¡GP: {circuit_info.first_grand_prix or 'N/A'}")
                logger.info(f"   ğŸ”„ åœˆæ•°: {circuit_info.number_of_laps or 'N/A'}")
                logger.info(f"   â±ï¸ æœ€å¿«åœˆé€Ÿ: {circuit_info.fastest_lap_time or 'N/A'}")
                logger.info(f"   ğŸ“ æ¯”èµ›è·ç¦»: {circuit_info.race_distance or 'N/A'} km")
                
                return circuit_info
                
            except asyncio.TimeoutError:
                logger.warning(f"â° è¯·æ±‚è¶…æ—¶ {circuit_id} (å°è¯• {attempt + 1}/{max_retries})")
            except Exception as e:
                logger.warning(f"âŒ æŠ“å–å¤±è´¥ {circuit_id} (å°è¯• {attempt + 1}/{max_retries}): {e}")
            
            if attempt < max_retries - 1:
                delay = 2 ** attempt
                logger.info(f"â³ ç­‰å¾… {delay} ç§’åé‡è¯•...")
                await asyncio.sleep(delay)
        
        logger.error(f"ğŸ’¥ æŠ“å–å¤±è´¥ï¼Œå·²è¾¾æœ€å¤§é‡è¯•æ¬¡æ•°: {circuit_id}")
        return None
    
    async def scrape_circuits_batch(self, circuit_ids: List[str], delay_between_requests: float = 3.0) -> Dict[str, Optional[CircuitInfo]]:
        """æ‰¹é‡æŠ“å–å¤šä¸ªèµ›é“ä¿¡æ¯"""
        results = {}
        total = len(circuit_ids)
        
        logger.info(f"ğŸš€ å¼€å§‹æ‰¹é‡æŠ“å– {total} ä¸ªèµ›é“")
        
        for i, circuit_id in enumerate(circuit_ids, 1):
            logger.info(f"ğŸ¯ è¿›åº¦ [{i}/{total}] å¤„ç†èµ›é“: {circuit_id}")
            
            try:
                circuit_info = await self.scrape_circuit_info_with_retry(circuit_id)
                results[circuit_id] = circuit_info
                
                if circuit_info:
                    status = "âœ… æˆåŠŸ"
                    if not circuit_info.is_complete():
                        status += f" (ç¼ºå¤±: {', '.join(circuit_info.missing_fields())})"
                else:
                    status = "âŒ å¤±è´¥"
                
                logger.info(f"   ç»“æœ: {status}")
                
            except Exception as e:
                logger.error(f"ğŸ’¥ å¤„ç†èµ›é“ {circuit_id} æ—¶å‘ç”Ÿå¼‚å¸¸: {e}")
                results[circuit_id] = None
            
            # è¯·æ±‚é—´å»¶è¿Ÿ
            if i < total:
                logger.info(f"â³ ç­‰å¾… {delay_between_requests} ç§’åç»§ç»­...")
                await asyncio.sleep(delay_between_requests)
        
        # è¾“å‡ºæ‰¹é‡å¤„ç†æ‘˜è¦
        successful = sum(1 for info in results.values() if info is not None)
        complete = sum(1 for info in results.values() if info and info.is_complete())
        
        logger.info(f"ğŸ“Š æ‰¹é‡å¤„ç†å®Œæˆ:")
        logger.info(f"   æ€»è®¡: {total}")
        logger.info(f"   æˆåŠŸ: {successful}")
        logger.info(f"   å®Œæ•´: {complete}")
        logger.info(f"   å¤±è´¥: {total - successful}")
        
        return results
    
    def validate_circuit_mapping_coverage(self, db_circuit_ids: List[str]) -> Dict[str, List[str]]:
        """éªŒè¯æ˜ å°„è¦†ç›–æƒ…å†µ"""
        mapped = []
        unmapped = []
        
        for circuit_id in db_circuit_ids:
            if circuit_id in self.circuit_mapping:
                mapped.append(circuit_id)
            else:
                unmapped.append(circuit_id)
        
        logger.info(f"ğŸ“‹ æ˜ å°„è¦†ç›–æƒ…å†µ:")
        logger.info(f"   å·²æ˜ å°„: {len(mapped)}/{len(db_circuit_ids)}")
        logger.info(f"   æœªæ˜ å°„: {unmapped if unmapped else 'æ— '}")
        
        return {
            "mapped": mapped,
            "unmapped": unmapped
        }


# æµ‹è¯•å‡½æ•°
async def test_scraper_v2():
    """æµ‹è¯•æ”¹è¿›ç‰ˆçˆ¬è™«"""
    test_circuits = ["spa", "silverstone", "monaco"]
    
    async with F1CircuitScraperV2() as scraper:
        # æµ‹è¯•æ˜ å°„éªŒè¯
        coverage = scraper.validate_circuit_mapping_coverage(test_circuits)
        
        # æ‰¹é‡æµ‹è¯•
        results = await scraper.scrape_circuits_batch(test_circuits, delay_between_requests=2.0)
        
        for circuit_id, info in results.items():
            print(f"\n=== {circuit_id.upper()} ===")
            if info:
                print(f"èµ›é“é•¿åº¦: {info.circuit_length} km")
                print(f"é¦–æ¬¡GP: {info.first_grand_prix}")
                print(f"åœˆæ•°: {info.number_of_laps}")
                print(f"æœ€å¿«åœˆé€Ÿ: {info.fastest_lap_time}")
                print(f"æ¯”èµ›è·ç¦»: {info.race_distance} km")
                print(f"æ•°æ®å®Œæ•´: {'âœ…' if info.is_complete() else 'âŒ'}")
            else:
                print("âŒ è·å–å¤±è´¥")


if __name__ == "__main__":
    asyncio.run(test_scraper_v2()) 